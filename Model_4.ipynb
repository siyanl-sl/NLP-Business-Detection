{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b25d934",
   "metadata": {},
   "source": [
    "# Model 4 - BERT + CNN (web_text included)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e713c1a",
   "metadata": {},
   "source": [
    "CNN can also be used for sentiment analysis. Embedded text also has two dimensions: embedded dimen& text length, very similar to 2d images.\n",
    "\n",
    "And in the context of two text sourses, I think of them as 2d images with 2 channels: one channel representing the text, and the other representing the web_text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba881d0",
   "metadata": {},
   "source": [
    "## 1) Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e6862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a478416",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('interview_case_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af351ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.copy()\n",
    "df['intact_name'] = df['intact_name'].str.rstrip('.') # remove the periord from the end of string\n",
    "df = df.fillna('')\n",
    "df['text'] = df['intact_name'].astype(str)+'. ' +df['SIC8_DESCRIPTION'].astype(str)+'. ' +df['4_Square_Description'].astype(str)\n",
    "df1 = df[['text','web_text','target_for_prediction']]\n",
    "df1 = df1.rename(columns={'target_for_prediction':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "502647a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>web_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218685 Ontario Inc o/a Swagat Banquet Hall. ba...</td>\n",
       "      <td>WE'RE MAJESTIC, REGAL, STYLISH&amp; EXPERTS IN ALL...</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Restaurant Pushap Sucrerie. eating places. sna...</td>\n",
       "      <td></td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transport Galf Inc. .</td>\n",
       "      <td></td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On The Go Courier. . specialized freight (exce...</td>\n",
       "      <td></td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484726 Alberta Ltd. local trucking, without s...</td>\n",
       "      <td></td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>Asdin Hospitality Ltd. o/a Best Western Plus F...</td>\n",
       "      <td></td>\n",
       "      <td>Hotel Accomodation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Casa Moda Fine Furnishing Inc. .</td>\n",
       "      <td>780-784-0638info@splendidfurnishings.caABOUT U...</td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>Jia De Trinh o/a Oakridge Dragon Restaurant Lt...</td>\n",
       "      <td></td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2000650 Ontario Inc. o/a Golden Bell Thai Rest...</td>\n",
       "      <td>Home Page Menu Lunch Specials Dinner Specials ...</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>L &amp; J Food Services Ltd o/a Ogopogo Mini Donut...</td>\n",
       "      <td></td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1563 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     218685 Ontario Inc o/a Swagat Banquet Hall. ba...   \n",
       "1     Restaurant Pushap Sucrerie. eating places. sna...   \n",
       "2                                Transport Galf Inc. .    \n",
       "3     On The Go Courier. . specialized freight (exce...   \n",
       "4     1484726 Alberta Ltd. local trucking, without s...   \n",
       "...                                                 ...   \n",
       "1558  Asdin Hospitality Ltd. o/a Best Western Plus F...   \n",
       "1559                  Casa Moda Fine Furnishing Inc. .    \n",
       "1560  Jia De Trinh o/a Oakridge Dragon Restaurant Lt...   \n",
       "1561  2000650 Ontario Inc. o/a Golden Bell Thai Rest...   \n",
       "1562  L & J Food Services Ltd o/a Ogopogo Mini Donut...   \n",
       "\n",
       "                                               web_text  \\\n",
       "0     WE'RE MAJESTIC, REGAL, STYLISH& EXPERTS IN ALL...   \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "1558                                                      \n",
       "1559  780-784-0638info@splendidfurnishings.caABOUT U...   \n",
       "1560                                                      \n",
       "1561  Home Page Menu Lunch Specials Dinner Specials ...   \n",
       "1562                                                      \n",
       "\n",
       "                           label  \n",
       "0                     Restaurant  \n",
       "1                     Restaurant  \n",
       "2     Trucking & Hauling Service  \n",
       "3     Trucking & Hauling Service  \n",
       "4     Trucking & Hauling Service  \n",
       "...                          ...  \n",
       "1558          Hotel Accomodation  \n",
       "1559  Trucking & Hauling Service  \n",
       "1560                  Restaurant  \n",
       "1561                  Restaurant  \n",
       "1562                  Restaurant  \n",
       "\n",
       "[1563 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32875521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(df1, test_size=0.1, random_state=25, stratify = df1.label)\n",
    "train_data, valid_data = train_test_split(training_data, test_size=0.1, random_state=25, stratify = training_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caf7b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 1265\n",
      "validation data size: 141\n",
      "testing data size: 157\n"
     ]
    }
   ],
   "source": [
    "print(f'training data size: {train_data.shape[0]}')\n",
    "print(f'validation data size: {valid_data.shape[0]}')\n",
    "print(f'testing data size: {test_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1a47c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save three datasets, for later torchtext use\n",
    "train_data.to_csv('./data2/train.csv',index=False)\n",
    "valid_data.to_csv('./data2/valid.csv',index=False)\n",
    "test_data.to_csv('./data2/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc5b21",
   "metadata": {},
   "source": [
    "## 2) Prepare Data & Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3674980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741a0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b95c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaba5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d30aa110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2] # we have to add two tokens: at the beginning and end of the text\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3edc115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2979aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('text', TEXT), ('web_text', TEXT), ('label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f694cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'data2',\n",
    "                                        train = 'train.csv',\n",
    "                                        validation = 'valid.csv',\n",
    "                                        test = 'test.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e1268b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [22431, 19961, 2620, 2620, 4561, 4297, 1012, 1004, 23968, 1005, 1055, 10733, 1012, 10733, 7884, 1012], 'web_text': [], 'label': 'Restaurant'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54f416f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'Restaurant': 0, 'Trucking & Hauling Service': 1, 'Hotel Accomodation': 2})\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19192d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 # consider the samll dataset and limited computational resources, I set a small batch size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3b427",
   "metadata": {},
   "source": [
    "## 3) Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b642693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b7cf383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1df76196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class BERTCNNSentiment(nn.Module):\n",
    "    def __init__(self, bert, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 2, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "    def forward(self, text, web_text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            text_embedded = self.bert(text)[0]  # freeze the bert para\n",
    "            \n",
    "        #text_embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        text_embedded_pad = F.pad(text_embedded, (0, 0, 0, max_input_length-len(text_embedded)),\"constant\", 0)\n",
    "                \n",
    "        #text_embedded_pad = [batch size, 512, emb dim]\n",
    "        \n",
    "        #web_text = [batch size, sent len]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            web_text_embedded = self.bert(web_text)[0]  # freeze the bert para\n",
    "        \n",
    "        #web_text_embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        web_text_embedded_pad = F.pad(text_embedded, (0, 0, 0, max_input_length-len(text_embedded)),\"constant\", 0)\n",
    "        \n",
    "        #web_text_embedded_pad = [batch size, 512, emb dim]\n",
    "        \n",
    "        embedded = torch.stack((text_embedded_pad, web_text_embedded_pad), dim=1) # stack two embedded, now channel = 2\n",
    "        \n",
    "        #embedded = [batch size, 2, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdf7f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3]\n",
    "OUTPUT_DIM = len(LABEL.vocab)\n",
    "DROPOUT = 0.1\n",
    "PAD_IDX = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "\n",
    "model4 = BERTCNNSentiment(bert, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b13adab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 110,251,043 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model4):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1358385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# too many parameters to train, I will freeze the bert para, due to the limited sources\n",
    "for name, param in model4.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d08d6d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 768,803 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model4):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52286101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convs.0.weight\n",
      "convs.0.bias\n",
      "convs.1.weight\n",
      "convs.1.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model4.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6634e9",
   "metadata": {},
   "source": [
    "## 4) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52957b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils.class_weight as class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4099f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data2/train.csv')\n",
    "train_Y = train_df.label\n",
    "train_Y = train_Y.apply(lambda x: 0 if x=='Restaurant' else 1 if x=='Trucking & Hauling Service' else 2) # according to the LABEL.vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e660e702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2], y=[0 0 1 ... 2 1 0] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.5541, 0.9945, 5.2708])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights=class_weight.compute_class_weight('balanced',np.unique(train_Y),train_Y.to_numpy())\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1bca83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model4.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights) # to deal with the imbalanced dataset\n",
    "\n",
    "model4 = model4.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "403e4bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    \"\"\"\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ef081ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text, batch.web_text)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label.long())\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label.long())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb96b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text, batch.web_text)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label.long())\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.label.long())\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "befb88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cafc3057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 24m 20s\n",
      "\tTrain Loss: 0.629 | Train Acc: 78.36%\n",
      "\t Val. Loss: 0.617 |  Val. Acc: 83.55%\n",
      "Epoch: 02 | Epoch Time: 24m 4s\n",
      "\tTrain Loss: 0.314 | Train Acc: 88.98%\n",
      "\t Val. Loss: 0.459 |  Val. Acc: 83.01%\n",
      "Epoch: 03 | Epoch Time: 24m 2s\n",
      "\tTrain Loss: 0.281 | Train Acc: 89.45%\n",
      "\t Val. Loss: 0.583 |  Val. Acc: 87.18%\n",
      "Epoch: 04 | Epoch Time: 22m 57s\n",
      "\tTrain Loss: 0.276 | Train Acc: 89.77%\n",
      "\t Val. Loss: 0.495 |  Val. Acc: 90.12%\n",
      "Epoch: 05 | Epoch Time: 23m 17s\n",
      "\tTrain Loss: 0.186 | Train Acc: 93.59%\n",
      "\t Val. Loss: 0.513 |  Val. Acc: 86.65%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model4, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model4, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model4.state_dict(), 'model4.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc66f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
