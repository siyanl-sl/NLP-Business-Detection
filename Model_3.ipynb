{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb9dc1a",
   "metadata": {},
   "source": [
    "Previous notebook goes through data loading, EDA, and modeling. And web_text is ignored when I build and train the model. I use BERT as encoder, followed by MLP and RNN respectively. The bet model(BERT+RNN) performance on validation data is around 90%.\n",
    "\n",
    "In this session, I will consider web_text, feed it to the model to see whether it can help boost model accuracy.\n",
    "\n",
    "Considering web_text is very different from the first three columns, I will encode them respectively using BERT. Then, use MLP or CNN to decode the information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b25d934",
   "metadata": {},
   "source": [
    "# Model 3 - BERT + MLP (web_text included)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8223979b",
   "metadata": {},
   "source": [
    "Very similar to model 1: get the embedded `[cls token] ` of text and web_text separately, and convey them to MLP. \n",
    "\n",
    "The only difference from model 1 is: we need to flatten the input dimension at the beginning of MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a81745b",
   "metadata": {},
   "source": [
    "## 1) Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8e6862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a478416",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('interview_case_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf6e6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw.copy()\n",
    "df['intact_name'] = df['intact_name'].str.rstrip('.') # remove the periord from the end of string\n",
    "df = df.fillna('')\n",
    "df['text'] = df['intact_name'].astype(str)+'. ' +df['SIC8_DESCRIPTION'].astype(str)+'. ' +df['4_Square_Description'].astype(str)\n",
    "df1 = df[['text','web_text','target_for_prediction']]\n",
    "df1 = df1.rename(columns={'target_for_prediction':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefbc874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>web_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>218685 Ontario Inc o/a Swagat Banquet Hall. ba...</td>\n",
       "      <td>WE'RE MAJESTIC, REGAL, STYLISH&amp; EXPERTS IN ALL...</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Restaurant Pushap Sucrerie. eating places. sna...</td>\n",
       "      <td></td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transport Galf Inc. .</td>\n",
       "      <td></td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On The Go Courier. . specialized freight (exce...</td>\n",
       "      <td></td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1484726 Alberta Ltd. local trucking, without s...</td>\n",
       "      <td></td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>Asdin Hospitality Ltd. o/a Best Western Plus F...</td>\n",
       "      <td></td>\n",
       "      <td>Hotel Accomodation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>Casa Moda Fine Furnishing Inc. .</td>\n",
       "      <td>780-784-0638info@splendidfurnishings.caABOUT U...</td>\n",
       "      <td>Trucking &amp; Hauling Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>Jia De Trinh o/a Oakridge Dragon Restaurant Lt...</td>\n",
       "      <td></td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>2000650 Ontario Inc. o/a Golden Bell Thai Rest...</td>\n",
       "      <td>Home Page Menu Lunch Specials Dinner Specials ...</td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1562</th>\n",
       "      <td>L &amp; J Food Services Ltd o/a Ogopogo Mini Donut...</td>\n",
       "      <td></td>\n",
       "      <td>Restaurant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1563 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     218685 Ontario Inc o/a Swagat Banquet Hall. ba...   \n",
       "1     Restaurant Pushap Sucrerie. eating places. sna...   \n",
       "2                                Transport Galf Inc. .    \n",
       "3     On The Go Courier. . specialized freight (exce...   \n",
       "4     1484726 Alberta Ltd. local trucking, without s...   \n",
       "...                                                 ...   \n",
       "1558  Asdin Hospitality Ltd. o/a Best Western Plus F...   \n",
       "1559                  Casa Moda Fine Furnishing Inc. .    \n",
       "1560  Jia De Trinh o/a Oakridge Dragon Restaurant Lt...   \n",
       "1561  2000650 Ontario Inc. o/a Golden Bell Thai Rest...   \n",
       "1562  L & J Food Services Ltd o/a Ogopogo Mini Donut...   \n",
       "\n",
       "                                               web_text  \\\n",
       "0     WE'RE MAJESTIC, REGAL, STYLISH& EXPERTS IN ALL...   \n",
       "1                                                         \n",
       "2                                                         \n",
       "3                                                         \n",
       "4                                                         \n",
       "...                                                 ...   \n",
       "1558                                                      \n",
       "1559  780-784-0638info@splendidfurnishings.caABOUT U...   \n",
       "1560                                                      \n",
       "1561  Home Page Menu Lunch Specials Dinner Specials ...   \n",
       "1562                                                      \n",
       "\n",
       "                           label  \n",
       "0                     Restaurant  \n",
       "1                     Restaurant  \n",
       "2     Trucking & Hauling Service  \n",
       "3     Trucking & Hauling Service  \n",
       "4     Trucking & Hauling Service  \n",
       "...                          ...  \n",
       "1558          Hotel Accomodation  \n",
       "1559  Trucking & Hauling Service  \n",
       "1560                  Restaurant  \n",
       "1561                  Restaurant  \n",
       "1562                  Restaurant  \n",
       "\n",
       "[1563 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814f7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_data, test_data = train_test_split(df1, test_size=0.1, random_state=25, stratify = df1.label)\n",
    "train_data, valid_data = train_test_split(training_data, test_size=0.1, random_state=25, stratify = training_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1790076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 1265\n",
      "validation data size: 141\n",
      "testing data size: 157\n"
     ]
    }
   ],
   "source": [
    "print(f'training data size: {train_data.shape[0]}')\n",
    "print(f'validation data size: {valid_data.shape[0]}')\n",
    "print(f'testing data size: {test_data.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af64ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save three datasets, for later torchtext use\n",
    "train_data.to_csv('./data2/train.csv',index=False)\n",
    "valid_data.to_csv('./data2/valid.csv',index=False)\n",
    "test_data.to_csv('./data2/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303e1e85",
   "metadata": {},
   "source": [
    "## 2) Prepare Data & Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e167f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0228985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85a4446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85432cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddaca646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2] # we have to add two tokens: at the beginning and end of the text\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66f1f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a043022",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('text', TEXT), ('web_text', TEXT), ('label', LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c5d1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
    "                                        path = 'data2',\n",
    "                                        train = 'train.csv',\n",
    "                                        validation = 'valid.csv',\n",
    "                                        test = 'test.csv',\n",
    "                                        format = 'csv',\n",
    "                                        fields = fields,\n",
    "                                        skip_header = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59fa0f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': [22431, 19961, 2620, 2620, 4561, 4297, 1012, 1004, 23968, 1005, 1055, 10733, 1012, 10733, 7884, 1012], 'web_text': [], 'label': 'Restaurant'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f29919d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(None, {'Restaurant': 0, 'Trucking & Hauling Service': 1, 'Hotel Accomodation': 2})\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(train_data)\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "985c8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16 # consider the samll dataset and limited computational resources, I set a small batch size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    sort = False,\n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3505dfa",
   "metadata": {},
   "source": [
    "## 3) Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f006e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af9018f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BERTMLPSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 output_dim\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.out = nn.Sequential(nn.Flatten(), #we have two-channel inputs(text & web_text), reshape them into a one-dimensional tensor\n",
    "                    nn.Linear(embedding_dim*2,128),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(128, output_dim)) # input dimension = hidden_size\n",
    "        \n",
    "        \n",
    "    def forward(self, text, web_text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            text_embedded = self.bert(text)[1]  # freeze the bert para, get the representation of [cls] token\n",
    "        \n",
    "        #text_embedded = [batch size, 1, emb dim]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            web_text_embedded = self.bert(web_text)[1]\n",
    "                \n",
    "        #web_text_embedded = [batch size, 1, emb dim]\n",
    "        \n",
    "        embedded = torch.stack((text_embedded, web_text_embedded), dim=1) # stack two embedded, now channel = 2\n",
    "        \n",
    "        #embedded = [batch size, 2, 1, emb dim]\n",
    "        \n",
    "        output = self.out(embedded)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c2b0e742",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 3\n",
    "\n",
    "model3 = BERTMLPSentiment(bert,\n",
    "                         OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "551fe9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# too many parameters to train, I will freeze the bert para, due to the limited sources\n",
    "for name, param in model3.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a3a2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 197,123 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model3):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7b88598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.1.weight\n",
      "out.1.bias\n",
      "out.3.weight\n",
      "out.3.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model3.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e33fb8",
   "metadata": {},
   "source": [
    "## 4) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2663668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.utils.class_weight as class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "055a489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data2/train.csv')\n",
    "train_Y = train_df.label\n",
    "train_Y = train_Y.apply(lambda x: 0 if x=='Restaurant' else 1 if x=='Trucking & Hauling Service' else 2) # according to the LABEL.vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a8b54fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5541, 0.9945, 5.2708])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights=class_weight.compute_class_weight('balanced',np.unique(train_Y),train_Y.to_numpy())\n",
    "class_weights=torch.tensor(class_weights,dtype=torch.float)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "679d6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model3.parameters())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights) # to deal with the imbalanced dataset\n",
    "\n",
    "model3 = model3.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e228fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch\n",
    "    \"\"\"\n",
    "    top_pred = preds.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52ad917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text, batch.web_text)\n",
    "        \n",
    "        loss = criterion(predictions, batch.label.long())\n",
    "        \n",
    "        acc = categorical_accuracy(predictions, batch.label.long())\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "657db42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text, batch.web_text)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label.long())\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, batch.label.long())\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c23ee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9979b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 24m 9s\n",
      "\tTrain Loss: 1.125 | Train Acc: 30.86%\n",
      "\t Val. Loss: 1.160 |  Val. Acc: 57.85%\n",
      "Epoch: 02 | Epoch Time: 23m 52s\n",
      "\tTrain Loss: 1.096 | Train Acc: 48.59%\n",
      "\t Val. Loss: 1.072 |  Val. Acc: 57.32%\n",
      "Epoch: 03 | Epoch Time: 22m 38s\n",
      "\tTrain Loss: 1.068 | Train Acc: 48.98%\n",
      "\t Val. Loss: 1.058 |  Val. Acc: 44.50%\n",
      "Epoch: 04 | Epoch Time: 22m 51s\n",
      "\tTrain Loss: 1.067 | Train Acc: 45.00%\n",
      "\t Val. Loss: 1.051 |  Val. Acc: 50.75%\n",
      "Epoch: 05 | Epoch Time: 23m 6s\n",
      "\tTrain Loss: 1.068 | Train Acc: 50.39%\n",
      "\t Val. Loss: 1.038 |  Val. Acc: 41.93%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model3, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model3, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model3.state_dict(), 'model3.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a6abb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
